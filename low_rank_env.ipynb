{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Low Rank MDPs Oracles\n",
    "\n",
    "In this notebook we will implement some basic Low-Rank MDPs both finite and infinite such as Simplex Feature MDPs and Block MDPs. This environments will be the \"truth\" that we want to approximate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplex MDPs\n",
    "### Finite State and Action Space\n",
    "Since in this case we have finite State and Action Spaces, we will use a one hot enconding representation of this spaces, were each element of this sets is assign a number in $\\mathcal{N}_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = 8 #Number of actions\n",
    "S = 10 #Number of states\n",
    "d = 3 #Rank of the MDP (Number of Latent Variables in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_mat_to_simplex(M, d=1):\n",
    "    \"\"\"This function projects all the column vectors of the Matrix `M` (m x n) onto \n",
    "    the standard simplex of dimension `m`. Taken from: \n",
    "    https://www.researchgate.net/publication/343831904_NumPy_SciPy_Recipes_for_Data_Science_Projections_onto_the_Standard_Simplex \n",
    "    A more simple way would be to just use a softmax over a random vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    m, n = M.shape\n",
    "\n",
    "    S = np.sort(M, axis=0)[::-1]\n",
    "    C = np.cumsum(S, axis=0) - d\n",
    "    H = S - C / (np.arange(m) + 1).reshape(m, 1)\n",
    "    H[H <= 0] = np.inf\n",
    "\n",
    "    r = np.argmin(H, axis=0)\n",
    "    t = C[r, np.arange(n)] / (r + 1)\n",
    "\n",
    "    Y = M - t\n",
    "    Y[Y < 0] = 0\n",
    "    return Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Feature Space from random vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15185472 0.60637257 0.24177272]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "# M = np.random.uniform(low=0, high=d, size=(d, S * A)) #One d-dimensional column vector for each (s, a) pair\n",
    "# P = proj_mat_to_simplex(M).T.reshape((S, A, d))\n",
    "M = np.random.uniform(low=-d, high=d, size=(S, A, d)) \n",
    "P = softmax(M, axis=2)\n",
    "Phi = lambda s,a: P[s, a, :] #Phi(S_0, A_0) \\in R^d\n",
    "print(Phi(0,0))\n",
    "print(sum(Phi(0,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a posteriori distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26021562 0.07329655 0.22941355]\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "U = np.random.uniform(0, 3, (S, d)) #One vector for each dimension \n",
    "U = softmax(U, axis=0)\n",
    "Mu = lambda s:  U[s, :].T # s entre 0 y S-1 \n",
    "print(Mu(0))\n",
    "print(sum(U[:,0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7807669790859032\n"
     ]
    }
   ],
   "source": [
    "T = lambda s, a, s_: np.dot(Phi(s, a), Mu(s_))\n",
    "print(T(0, 2, 1)) #Probabilidad de pasar de s_0 a s_1 por medio de s_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify regularity conditions of our construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9999999999999996\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "integral = np.zeros(d)\n",
    "\n",
    "for s in range(S):\n",
    "    integral += Mu(s)\n",
    "\n",
    "norm_sqr = np.linalg.norm(integral) ** 2\n",
    "print(norm_sqr)\n",
    "print(np.isclose(norm_sqr, d, rtol=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats.distributions import norm\n",
    "\n",
    "def unif_over_states(states=100):\n",
    "    return np.random.randint(low=0, high=states)\n",
    "\n",
    "class SimplexEnvironment:\n",
    "    def __init__(self, states=100, actions=20, bell_rank=10, intial_distrib=unif_over_states):\n",
    "        self.S = states\n",
    "        self.A = actions\n",
    "        self.d = bell_rank\n",
    "        self.initial_distrib = intial_distrib\n",
    "\n",
    "        M = np.random.uniform(0, 3, (self.d, self.S * self.A)) #One d-dimensional column vector for each (s, a) pair\n",
    "        \n",
    "        self.P = self.proj_mat_to_simplex(M).T.reshape((self.S, self.A, self.d))\n",
    "        self.Phi = lambda s,a: self.P[s, a, :]\n",
    "\n",
    "        U = np.random.uniform(0, 3, (self.S, self.d)) #One vector for each dimension \n",
    "        self.U = self.proj_mat_to_simplex(U)\n",
    "        self.Mu = lambda s:  self.U[s, :].T # s entre 0 y S-1 \n",
    "        self.T = lambda s, a, s_: np.dot(self.Phi(s, a), self.Mu(s_))\n",
    "\n",
    "\n",
    "\n",
    "    def proj_mat_to_simplex(self, M, d=1):\n",
    "        \"\"\"This function projects all the column vectors of the Matrix `M` (m x n) onto \n",
    "        the standard simplex of dimension `m`. Taken from: \n",
    "        https://www.researchgate.net/publication/343831904_NumPy_SciPy_Recipes_for_Data_Science_Projections_onto_the_Standard_Simplex \"\"\"\n",
    "        m, n = M.shape\n",
    "\n",
    "        S = np.sort(M, axis=0)[::-1]\n",
    "        C = np.cumsum(S, axis=0) - d\n",
    "        H = S - C / (np.arange(m) + 1).reshape(m, 1)\n",
    "        H[H <= 0] = np.inf\n",
    "\n",
    "        r = np.argmin(H, axis=0)\n",
    "        t = C[r, np.arange(n)] / (r + 1)\n",
    "\n",
    "        Y = M - t\n",
    "        Y[Y < 0] = 0\n",
    "        return Y\n",
    "\n",
    "    def next_step_distrib(self, s, a):\n",
    "        return np.dot(self.Phi(s,a), self.U.T)\n",
    "\n",
    "    def next_step_state(self, s, a):\n",
    "        return np.random.choice(self.S, p=self.next_step_distrib(s,a))\n",
    "    \n",
    "    def next_step_reward(self, s, a):\n",
    "        return norm.rvs()\n",
    "    \n",
    "    def next_step(self, s, a):\n",
    "        \"\"\" \n",
    "        Gives the next state and reword for the given actions. \n",
    "        If `s` is the absorving state (i.e s == self.S - 1. Just by convention)\n",
    "        Then this will return 0 as reward and a state following the initial state distrib.\n",
    "        \"\"\"\n",
    "        if s == self.S - 1:\n",
    "            return self.first_step(), 0\n",
    "        else:\n",
    "            return self.next_step_state(s, a), self.next_step_reward(s, a)\n",
    "    \n",
    "    def first_step(self):\n",
    "        return self.initial_distrib(self.S)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate an Environment from the Simplex MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 1.002155018673309)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = SimplexEnvironment()\n",
    "env.next_step(0,0)\n",
    "# np.sum(env.P, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, -1.9631144612288514)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.next_step(0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation\n",
    "\n",
    "We have created a utility file in where there is a more complete version of the previous simplex environment.\n",
    "\n",
    "Know we will create some MDPs with such class and some walk data for each one following a uniform policy over actions. That will be the data we use in the implementation of the function approximation. Also is important that we save the MDPs so we can compare later the different algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import SimplexEnvironment\n",
    "from pickle import dump\n",
    "import os\n",
    "\n",
    "smallMDP = SimplexEnvironment(states=100, actions=10, bell_rank=3)\n",
    "dump(smallMDP, open(os.path.join(\"data\", \"mdps\", \"small\" ,\"small_mdp.bin\"), 'wb'))\n",
    "\n",
    "mediumMDP = SimplexEnvironment(states=400, actions=50, bell_rank=5)\n",
    "dump(mediumMDP, open(os.path.join(\"data\", \"mdps\", \"medium\" ,\"medium_mdp.bin\"), 'wb'))\n",
    "\n",
    "largeMDP = SimplexEnvironment(states=1000, actions=100, bell_rank=10)\n",
    "dump(largeMDP, open(os.path.join(\"data\", \"mdps\", \"large\" ,\"large_mdp.bin\"), 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating 414480 Steps: 100%|██████████| 414480/414480 [00:21<00:00, 19515.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 21.8 s\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from math import ceil\n",
    "from pickle import load, dump\n",
    "import numpy as np\n",
    "smallMDP = load(open(os.path.join(\"data\", \"mdps\", \"small\" ,\"small_mdp.bin\"), 'rb'))\n",
    "n = 30*ceil(smallMDP.A * smallMDP.d * smallMDP.S * np.log(smallMDP.S))\n",
    "path = smallMDP.simulate_n_steps(n)\n",
    "dump(path, open(os.path.join(\"data\", \"mdps\", \"small\" ,\"small_mdp_path.bin\"), 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290136 414480\n"
     ]
    }
   ],
   "source": [
    "# Train test splits\n",
    "from pickle import load, dump\n",
    "from random import shuffle\n",
    "from math import ceil\n",
    "small_path = load( open(os.path.join(\"data\", \"mdps\", \"small\" ,\"small_mdp_path.bin\"), 'rb'))\n",
    "shuffle(small_path)\n",
    "train_index = ceil(len(small_path) * 0.7)\n",
    "print(train_index, len(small_path))\n",
    "\n",
    "small_train_path = small_path[:train_index]\n",
    "small_test_path = small_path[train_index:] \n",
    "\n",
    "dump(small_train_path, open(os.path.join(\"data\", \"mdps\", \"small\" ,\"small_mdp_path_train.bin\"), 'wb'))\n",
    "dump(small_test_path, open(os.path.join(\"data\", \"mdps\", \"small\" ,\"small_mdp_path_test.bin\"), 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating 17974410 Steps: 100%|██████████| 17974410/17974410 [14:41<00:00, 20396.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14min 58s\n",
      "Wall time: 14min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from math import ceil\n",
    "from pickle import load, dump\n",
    "import numpy as np\n",
    "mediumMDP = load(open(os.path.join(\"data\", \"mdps\", \"medium\" ,\"medium_mdp.bin\"), 'rb'))\n",
    "n = 30*ceil(mediumMDP.A * mediumMDP.d * mediumMDP.S * np.log(mediumMDP.S))\n",
    "path = mediumMDP.simulate_n_steps(n)\n",
    "dump(path, open(os.path.join(\"data\", \"mdps\", \"medium\" ,\"medium_mdp_path.bin\"), 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caculate Optimal Policy a Value Function for the MDPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:00<00:09, 200.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.34 s\n",
      "Wall time: 1.54 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from utils import PolicyIteration\n",
    "from pickle import load, dump\n",
    "import numpy as np\n",
    "\n",
    "MDP = load( open(os.path.join(\"data\", \"mdps\", \"small\" ,\"small_mdp.bin\"), 'rb'))\n",
    "\n",
    "\n",
    "def reward(s_prev, a, s_next):\n",
    "    return np.log(s_prev + 1) + np.log(a + 1) + np.log(s_next + 1)\n",
    "\n",
    "def next_state_prob(s, a):\n",
    "    return MDP.Phi(s, a) @ MDP.U.T\n",
    "\n",
    "pol_iter = PolicyIteration(MDP.S , MDP.A, next_state_prob , reward)\n",
    "\n",
    "v, pol = pol_iter.run()\n",
    "saving = (v, pol)\n",
    "dump(saving, open(os.path.join(\"data\", \"mdps\", \"small\" ,\"small_mdp_optimals.bin\"), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block MDPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_arch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ae4df1c5943cf4748546a76d45f227f53fb8acff87095bbb53afeb5cd17aec1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
