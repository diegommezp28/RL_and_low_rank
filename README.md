# RL_and_low_rank
<div id="top"></div>
<!--
*** Thanks for checking out the Best-README-Template. If you have a suggestion
*** that would make this better, please fork the repo and create a pull request
*** or simply open an issue with the tag "enhancement".
*** Don't forget to give the project a star!
*** Thanks again! Now go create something AMAZING! :D
-->



<!-- PROJECT SHIELDS -->
<!--
*** I'm using markdown "reference style" links for readability.
*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).
*** See the bottom of this document for the declaration of the reference variables
*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.
*** https://www.markdownguide.org/basic-syntax/#reference-style-links
-->
[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]
[![MIT License][license-shield]][license-url]




<!-- PROJECT LOGO -->
<br />
<div align="center">
    <img src="https://user-images.githubusercontent.com/47110686/140454597-58fa49cf-744a-4d96-ba6e-54e0387bc073.png" alt="Logo" width="450" height="300">
  </a>


<h3 align="center">Applications of a Low-Rank Hypothesis for Solving Reinforcement Learning Problems</h3>

  <p align="center">
  
In this project we explore the implications of assuming and MDP (which is the mathematical framework in which Reinforcement Learning Lives) has a low-rank structure given by a latent variable space. There will be implementations of multiple algorithms designed to tackle this scenario as well as some more classical DP algorithms for RL such as Policy Iteration and Value Iteration. 

  </br>
    <a href="https://github.com/diegommezp28/RL_and_low_rank/issues">Report Bug</a>
    ·
  </p>
</div>



<!-- TABLE OF CONTENTS -->
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href="#about-the-project">About</a>
      <ul>
        <li><a href="#built-with">Built with</a></li>
      </ul>
    </li>
    <li>
      <a href="#getting-started">Intro</a>
      <ul>
        <li><a href="#prerequisites">Prerequisites</a></li>
        <li><a href="#installation">Installation</a></li>
      </ul>
    </li>
    <li><a href="#usage">Use</a></li>
    <li><a href="#license">License</a></li>
    <li><a href="#contact">Contact</a></li>
  </ol>
</details>



<!-- ABOUT THE PROJECT -->
## About
This project is part of my Bsc Thesis in Mathematics developes in the Universidad de los Andes at Bogotá, Colombia.


 <!-- ![image](https://user-images.githubusercontent.com/47110686/140454973-b1c7e6d5-f593-44b9-8c8f-f2ad8fbee495.png)

![image](https://user-images.githubusercontent.com/47110686/140455106-92ebd036-3800-4523-81dd-476ce8daafa4.png)

![image](https://user-images.githubusercontent.com/47110686/140455159-83d70615-09bb-4f05-a3cf-ba389d9afc1e.png) -->


<p align="right">(<a href="#top">back to top</a>)</p>



### Built With

* [Python](https://www.python.org/)
* [PyTorch](https://pytorch.org/)
* [Numpy](https://numpy.org/)

<p align="right">(<a href="#top">back to top</a>)</p>



<!-- GETTING STARTED -->
## Intro
The papers above are the main guides for these project

 ### Papers
 
 * [Learning Markov models via low-rank optimization](https://arxiv.org/abs/1907.00113)
 * [FLAMBE: Structural Complexity and Representation Learning of Low Rank MDPs](https://arxiv.org/abs/2006.10814)
 * [Representation Learning for Online and Offline RL in Low-rank MDPs](https://arxiv.org/abs/2110.04652    )

### Thesis
 * Original Spanish Thesis Doc is Located in this repo.

<p align="right">(<a href="#top">back to top</a>)</p>




<!-- LICENSE -->
## License

Distributed under the MIT License. See `LICENSE.txt` for more information.

<p align="right">(<a href="#top">back to top</a>)</p>



<!-- CONTACT -->
## Contact

Diego Gómez  - da.gomezp@uniandes.edu.co

Project Link: [https://github.com/diegommezp28/RL_and_low_rank](https://github.com/diegommezp28/RL_and_low_rank)

<p align="right">(<a href="#top">back to top</a>)</p>



<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
[contributors-shield]: https://img.shields.io/github/contributors/diegommezp28/RL_and_low_rank.svg?style=for-the-badge
[contributors-url]: https://github.com/diegommezp28/RL_and_low_rank/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/diegommezp28/RL_and_low_rank.svg?style=for-the-badge
[forks-url]: https://github.com/diegommezp28/RL_and_low_rank/network/members
[stars-shield]: https://img.shields.io/github/stars/diegommezp28/RL_and_low_rank.svg?style=for-the-badge
[stars-url]: https://github.com/diegommezp28/RL_and_low_rank/stargazers
[issues-shield]: https://img.shields.io/github/issues/diegommezp28/RL_and_low_rank.svg?style=for-the-badge
[issues-url]: https://github.com/diegommezp28/RL_and_low_rank/issues
[license-shield]: https://img.shields.io/github/license/diegommezp28/RL_and_low_rank.svg?style=for-the-badge
[license-url]: https://github.com/diegommezp28/RL_and_low_rank/blob/master/LICENSE.txt
[product-screenshot]: images/screenshot.png
